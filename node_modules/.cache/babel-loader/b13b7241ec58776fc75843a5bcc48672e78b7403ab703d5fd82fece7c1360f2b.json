{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useRef } from \"react\";\nexport function useVoiceOutput({\n  onEnd\n}) {\n  _s();\n  const audioRef = useRef(null);\n  async function speak(text) {\n    const apiKey = process.env.REACT_APP_ELEVENLABS_API_KEY;\n    const voiceId = process.env.REACT_APP_ELEVENLABS_VOICE_ID; // Your cloned voice ID\n    const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`;\n    const response = await fetch(url, {\n      method: \"POST\",\n      headers: {\n        \"xi-api-key\": apiKey,\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"audio/mpeg\"\n      },\n      body: JSON.stringify({\n        text,\n        model_id: \"eleven_multilingual_v2\",\n        voice_settings: {\n          stability: 0.5,\n          similarity_boost: 0.8\n        }\n      })\n    });\n    const audioBlob = await response.blob();\n    const audioUrl = URL.createObjectURL(audioBlob);\n    if (audioRef.current) {\n      audioRef.current.src = audioUrl;\n      audioRef.current.onended = onEnd;\n      audioRef.current.play();\n    }\n  }\n  return {\n    speak,\n    audioRef\n  };\n}\n_s(useVoiceOutput, \"0sm4EU6wFifmHvgu8ujVUSp82DM=\");","map":{"version":3,"names":["useRef","useVoiceOutput","onEnd","_s","audioRef","speak","text","apiKey","process","env","REACT_APP_ELEVENLABS_API_KEY","voiceId","REACT_APP_ELEVENLABS_VOICE_ID","url","response","fetch","method","headers","body","JSON","stringify","model_id","voice_settings","stability","similarity_boost","audioBlob","blob","audioUrl","URL","createObjectURL","current","src","onended","play"],"sources":["C:/joebot/src/hooks/useVoiceOutput.js"],"sourcesContent":["import { useRef } from \"react\";\r\n\r\nexport function useVoiceOutput({ onEnd }) {\r\n  const audioRef = useRef(null);\r\n\r\n  async function speak(text) {\r\n    const apiKey = process.env.REACT_APP_ELEVENLABS_API_KEY;\r\n    const voiceId = process.env.REACT_APP_ELEVENLABS_VOICE_ID; // Your cloned voice ID\r\n    const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`;\r\n    const response = await fetch(url, {\r\n      method: \"POST\",\r\n      headers: {\r\n        \"xi-api-key\": apiKey,\r\n        \"Content-Type\": \"application/json\",\r\n        \"Accept\": \"audio/mpeg\",\r\n      },\r\n      body: JSON.stringify({\r\n        text,\r\n        model_id: \"eleven_multilingual_v2\",\r\n        voice_settings: { stability: 0.5, similarity_boost: 0.8 }\r\n      }),\r\n    });\r\n    const audioBlob = await response.blob();\r\n    const audioUrl = URL.createObjectURL(audioBlob);\r\n    if (audioRef.current) {\r\n      audioRef.current.src = audioUrl;\r\n      audioRef.current.onended = onEnd;\r\n      audioRef.current.play();\r\n    }\r\n  }\r\n\r\n  return { speak, audioRef };\r\n} "],"mappings":";AAAA,SAASA,MAAM,QAAQ,OAAO;AAE9B,OAAO,SAASC,cAAcA,CAAC;EAAEC;AAAM,CAAC,EAAE;EAAAC,EAAA;EACxC,MAAMC,QAAQ,GAAGJ,MAAM,CAAC,IAAI,CAAC;EAE7B,eAAeK,KAAKA,CAACC,IAAI,EAAE;IACzB,MAAMC,MAAM,GAAGC,OAAO,CAACC,GAAG,CAACC,4BAA4B;IACvD,MAAMC,OAAO,GAAGH,OAAO,CAACC,GAAG,CAACG,6BAA6B,CAAC,CAAC;IAC3D,MAAMC,GAAG,GAAG,+CAA+CF,OAAO,EAAE;IACpE,MAAMG,QAAQ,GAAG,MAAMC,KAAK,CAACF,GAAG,EAAE;MAChCG,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,YAAY,EAAEV,MAAM;QACpB,cAAc,EAAE,kBAAkB;QAClC,QAAQ,EAAE;MACZ,CAAC;MACDW,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBd,IAAI;QACJe,QAAQ,EAAE,wBAAwB;QAClCC,cAAc,EAAE;UAAEC,SAAS,EAAE,GAAG;UAAEC,gBAAgB,EAAE;QAAI;MAC1D,CAAC;IACH,CAAC,CAAC;IACF,MAAMC,SAAS,GAAG,MAAMX,QAAQ,CAACY,IAAI,CAAC,CAAC;IACvC,MAAMC,QAAQ,GAAGC,GAAG,CAACC,eAAe,CAACJ,SAAS,CAAC;IAC/C,IAAIrB,QAAQ,CAAC0B,OAAO,EAAE;MACpB1B,QAAQ,CAAC0B,OAAO,CAACC,GAAG,GAAGJ,QAAQ;MAC/BvB,QAAQ,CAAC0B,OAAO,CAACE,OAAO,GAAG9B,KAAK;MAChCE,QAAQ,CAAC0B,OAAO,CAACG,IAAI,CAAC,CAAC;IACzB;EACF;EAEA,OAAO;IAAE5B,KAAK;IAAED;EAAS,CAAC;AAC5B;AAACD,EAAA,CA9BeF,cAAc","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}